# ğŸ¤– **Guide d'Installation IA Gratuite pour Rivela**

## **ğŸ¯ Vue d'ensemble**

Rivela intÃ¨gre plusieurs options d'IA gratuites pour l'analyse financiÃ¨re :

1. **Ollama (RecommandÃ©)** - IA locale 100% gratuite
2. **Hugging Face** - API gratuite (30k req/mois)
3. **Cohere** - API spÃ©cialisÃ©e finance (5 req/min)
4. **Fallback** - Simulation locale (toujours disponible)

---

## **ğŸš€ Option 1 : Ollama (RecommandÃ©)**

### **Avantages**
- âœ… **100% Gratuit** et open source
- âœ… **DonnÃ©es privÃ©es** - reste sur votre machine
- âœ… **ModÃ¨les avancÃ©s** - Mistral, Llama 2, CodeLlama
- âœ… **Performance** - TrÃ¨s rapide en local
- âœ… **Hors ligne** - Fonctionne sans internet

### **Installation**

#### **Linux/macOS**
```bash
# Installation automatique
curl -fsSL https://ollama.ai/install.sh | sh

# Ou installation manuelle
# 1. TÃ©lÃ©chargez depuis https://ollama.ai
# 2. DÃ©compressez et installez
```

#### **Windows (WSL)**
```bash
# Dans WSL Ubuntu
curl -fsSL https://ollama.ai/install.sh | sh
```

### **Configuration**
```bash
# 1. DÃ©marrer Ollama
ollama serve

# 2. TÃ©lÃ©charger un modÃ¨le (dans un autre terminal)
ollama pull mistral
ollama pull llama2

# 3. Tester
ollama run mistral "Analyse cette situation financiÃ¨re"
```

### **VÃ©rification**
```bash
# Lister les modÃ¨les disponibles
ollama list

# Tester la connectivitÃ©
curl http://localhost:11434/api/tags
```

---

## **ğŸŒ Option 2 : Hugging Face**

### **Avantages**
- âœ… **30,000 requÃªtes/mois** gratuites
- âœ… **ModÃ¨les spÃ©cialisÃ©s** - GPT-J, BLOOM, T5
- âœ… **API simple** - REST facile Ã  utiliser
- âœ… **CommunautÃ© active** - Large Ã©cosystÃ¨me

### **Configuration**

1. **CrÃ©er un compte** sur [Hugging Face](https://huggingface.co)
2. **Obtenir un token** dans [Settings > Tokens](https://huggingface.co/settings/tokens)
3. **Configurer l'environnement** :

```bash
# CrÃ©er le fichier .env.local
cp .env.example .env.local

# Ã‰diter le fichier
nano .env.local

# Ajouter votre token
REACT_APP_HUGGING_FACE_TOKEN=hf_your_token_here
```

### **ModÃ¨les recommandÃ©s**
- `microsoft/DialoGPT-medium` - Conversation naturelle
- `gpt2` - GÃ©nÃ©ration de texte
- `t5-base` - Traitement de texte

---

## **ğŸ§  Option 3 : Cohere**

### **Avantages**
- âœ… **SpÃ©cialisÃ© finance** - ModÃ¨les optimisÃ©s
- âœ… **5 requÃªtes/minute** gratuites
- âœ… **FiabilitÃ© Ã©levÃ©e** - Service stable
- âœ… **Analyse avancÃ©e** - Insights spÃ©cialisÃ©s

### **Configuration**

1. **CrÃ©er un compte** sur [Cohere Dashboard](https://dashboard.cohere.ai)
2. **Obtenir une clÃ© API** dans [API Keys](https://dashboard.cohere.ai/api-keys)
3. **Configurer l'environnement** :

```bash
# Ajouter Ã  .env.local
REACT_APP_COHERE_TOKEN=your_cohere_token_here
```

### **ModÃ¨les disponibles**
- `command` - GÃ©nÃ©ration de texte
- `command-light` - Version rapide
- `summarize` - RÃ©sumÃ© de texte

---

## **âš¡ Option 4 : Fallback (Toujours disponible)**

### **CaractÃ©ristiques**
- âœ… **Toujours fonctionnel** - Pas de dÃ©pendance externe
- âœ… **Hors ligne** - Fonctionne sans internet
- âœ… **Rapide** - RÃ©ponse immÃ©diate
- âœ… **Basique** - Algorithmes prÃ©dÃ©finis

### **Utilisation**
Aucune configuration requise. Fonctionne automatiquement si les autres providers ne sont pas disponibles.

---

## **ğŸ”§ Configuration de l'application**

### **1. Variables d'environnement**
```bash
# Copier le fichier d'exemple
cp .env.example .env.local

# Ã‰diter avec vos tokens
nano .env.local
```

### **2. DÃ©marrer l'application**
```bash
# Installer les dÃ©pendances
npm install

# DÃ©marrer en mode dÃ©veloppement
npm run dev
```

### **3. Tester la configuration**
1. Ouvrir l'application
2. Aller dans **ParamÃ¨tres > Configuration IA**
3. Cliquer sur **"Tester"** pour vÃ©rifier les providers
4. Choisir votre provider prÃ©fÃ©rÃ©

---

## **ğŸ“Š Comparaison des options**

| Provider | CoÃ»t | Vitesse | PrÃ©cision | ConfidentialitÃ© | Setup |
|----------|------|---------|-----------|-----------------|-------|
| **Ollama** | Gratuit | âš¡âš¡âš¡ | â­â­â­â­ | ğŸ”’ğŸ”’ğŸ”’ | âš™ï¸ |
| **Hugging Face** | 30k/mois | âš¡âš¡ | â­â­â­ | ğŸ”’ğŸ”’ | âœ… |
| **Cohere** | 5/min | âš¡âš¡âš¡ | â­â­â­â­â­ | ğŸ”’ğŸ”’ | âœ… |
| **Fallback** | Gratuit | âš¡âš¡âš¡âš¡ | â­â­ | ğŸ”’ğŸ”’ğŸ”’ | âœ… |

---

## **ğŸš¨ DÃ©pannage**

### **Ollama ne dÃ©marre pas**
```bash
# VÃ©rifier le service
sudo systemctl status ollama

# RedÃ©marrer
sudo systemctl restart ollama

# VÃ©rifier les logs
journalctl -u ollama -f
```

### **Erreur de connectivitÃ©**
```bash
# Tester la connexion
curl http://localhost:11434/api/tags

# VÃ©rifier le port
netstat -tlnp | grep 11434
```

### **Token Hugging Face invalide**
1. VÃ©rifier le token sur [Hugging Face](https://huggingface.co/settings/tokens)
2. RÃ©gÃ©nÃ©rer si nÃ©cessaire
3. Mettre Ã  jour `.env.local`

### **Limite Cohere atteinte**
- Attendre 1 minute (limite 5 req/min)
- VÃ©rifier l'utilisation sur [Dashboard](https://dashboard.cohere.ai)

---

## **ğŸ¯ Recommandations**

### **Pour le dÃ©veloppement**
- Utilisez **Ollama** pour les tests rapides
- **Fallback** comme backup

### **Pour la production**
- **Ollama** si vous avez les ressources serveur
- **Hugging Face** pour la simplicitÃ©
- **Cohere** pour la prÃ©cision financiÃ¨re

### **Pour la confidentialitÃ©**
- **Ollama** - DonnÃ©es 100% privÃ©es
- **Fallback** - Aucune donnÃ©e externe

---

## **ğŸ“š Ressources**

- [Documentation Ollama](https://ollama.ai/docs)
- [API Hugging Face](https://huggingface.co/docs/api-inference)
- [API Cohere](https://docs.cohere.com)
- [Guide des modÃ¨les](https://huggingface.co/models)

---

## **ğŸ†˜ Support**

Si vous rencontrez des problÃ¨mes :

1. **VÃ©rifiez les logs** dans la console du navigateur
2. **Testez la connectivitÃ©** dans les paramÃ¨tres IA
3. **Consultez la documentation** des providers
4. **Utilisez le fallback** en cas d'urgence

**Rivela fonctionnera toujours avec le mode fallback, mÃªme sans IA externe !** ğŸ‰